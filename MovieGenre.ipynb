{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer,PorterStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=\"Genre Classification Dataset/train_data.txt\"\n",
    "train=pd.read_csv(tp,sep=':::',names=['ID','TITLE','GENRE','DESCRIPTION'],engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tep=\"Genre Classification Dataset/test_data.txt\"\n",
    "test=pd.read_csv(tep,sep=\":::\",names=['id','TITLE','DESCRIPTION'],engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "sns.countplot(data=train,x='GENRE',order=train['GENRE'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=LancasterStemmer()\n",
    "nltk.download('stopwords')\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))  # Stopwords set\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@\\S+', '', text)  # replace twitter accounts with a space\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'.pic\\S+', '', text)\n",
    "    text = re.sub(r'#','',text)\n",
    "    text = re.sub(r'[^a-zA-Z+]', ' ', text)  # Change to replace non-characters with a space\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Use the predefined stop_words variable instead of redefining it inside the function\n",
    "    text = \" \".join([i for i in words if i not in stop_words and len(i) > 2])\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Replace multiple spaces with a single space\n",
    "    return text\n",
    "\n",
    "train[\"TextCleaning\"] = train[\"DESCRIPTION\"].apply(clean_text)\n",
    "test[\"TextCleaning\"] = test[\"DESCRIPTION\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "train['TextCleaning'] = train['TextCleaning'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "test['TextCleaning'] = test['TextCleaning'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['GENRE'] = le.fit_transform(train['GENRE'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.loc[:,['TextCleaning', 'GENRE']]\n",
    "test_df = test.loc[:,['TextCleaning', 'TITLE']]\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train_df['TextCleaning'] ,train['GENRE'] , test_size=0.2 , shuffle=True , random_state = 42)\n",
    "print(f'Split data into train and eval sets')\n",
    "print(f'Traning Set\\t: {len(X_train)}\\nValidation Set\\t: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "X_train_tfidf = vectorize.fit_transform(X_train)\n",
    "\n",
    "X_test_tfidf = vectorize.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "sv_model = LinearSVC(max_iter=1000)\n",
    "sv_model.fit(X_train_tfidf,y_train)\n",
    "predict_sv=sv_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predict_sv))\n",
    "sv_accuracy = accuracy_score(y_test,predict_sv)\n",
    "print('Support vector accuracy is: {:.2f}%'.format(sv_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model=LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf,y_train)\n",
    "predict_lr=lr_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predict_lr))\n",
    "lr_accuracy = accuracy_score(y_test, predict_lr)\n",
    "print('Logistic Regression accuracy is: {:.2f}%'.format(lr_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv_model=MultinomialNB()\n",
    "nv_model.fit(X_train_tfidf,y_train)\n",
    "predict_nv=nv_model.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predict_nv))\n",
    "nv_accuracy = accuracy_score(y_test, predict_nv)\n",
    "print('Logistic Regression accuracy is: {:.2f}%'.format(nv_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['LogisticRegression', 'MultinomialNB','SVC']\n",
    "accuracy= [lr_accuracy, nv_accuracy, sv_accuracy]\n",
    "\n",
    "FinalResult=pd.DataFrame({'Algorithm':columns, 'Accuracy':accuracy})\n",
    "\n",
    "FinalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15,5))\n",
    "plt.plot(FinalResult.Algorithm,accuracy,label=\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
